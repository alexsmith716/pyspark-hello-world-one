# pyspark-hello-world-one

Of course, the solution to a working Spark environment is 30 times simpler than documention would imply.


### Command:

`% spark-submit pyspark-hello-world-one.py`


### Output:

`21/04/01 16:55:18 INFO DAGScheduler: Job 2 finished: collect at /pyspark-hello-world-one/pyspark-hello-world-one.py:9, took 0.118586 s`

`
l: 3
o: 2
H: 1
W: 1
e: 1
d: 1
 : 1
r: 1
`
